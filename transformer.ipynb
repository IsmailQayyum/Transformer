{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example sentence: `I love you`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), torch.Size([3]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([0,1,2])\n",
    "input,input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5389, -0.1476,  0.0763,  1.2217],\n",
       "         [-0.8461, -0.1356,  1.5055,  0.2531],\n",
       "         [-0.6635,  0.4190, -1.3850, -0.0317]], grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Embedding\n",
    "\n",
    "embedding = Embedding(3,4)\n",
    "embedded_sentence =embedding(input)\n",
    "embedded_sentence,embedded_sentence.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q_vector=[]\n",
    "k_vector=[]\n",
    "v_vector=[]\n",
    "q_vector.clear()\n",
    "k_vector.clear()\n",
    "v_vector.clear()\n",
    "\n",
    "Wq = torch.rand(4,3)\n",
    "Wk = torch.rand(4,3)\n",
    "Wv = torch.rand(4,3)\n",
    "\n",
    "\n",
    "for word in embedded_sentence:\n",
    "    q_vector.append(torch.matmul(word.unsqueeze(0),Wq))\n",
    "    k_vector.append(torch.matmul(word.unsqueeze(0),Wk))\n",
    "    v_vector.append(torch.matmul(word.unsqueeze(0),Wv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.2723, 0.2406, 0.7984]], grad_fn=<MmBackward0>),\n",
       " tensor([[0.2367, 0.7711, 0.9227]], grad_fn=<MmBackward0>),\n",
       " tensor([[-0.7887, -0.5633, -1.4106]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[1.1163, 0.6530, 0.1827]], grad_fn=<MmBackward0>),\n",
       "  tensor([[1.0899, 0.0861, 0.9851]], grad_fn=<MmBackward0>),\n",
       "  tensor([[-0.9386,  0.1854, -0.7626]], grad_fn=<MmBackward0>)],\n",
       " torch.Size([1, 3]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_vector , k_vector[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.7486, 0.7158, 0.7152]], grad_fn=<MmBackward0>),\n",
       " tensor([[0.2388, 1.0195, 0.2980]], grad_fn=<MmBackward0>),\n",
       " tensor([[-0.5178, -1.7597, -1.0042]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.1163, 0.6530, 0.1827]], grad_fn=<MmBackward0>),\n",
       " tensor([[1.0899, 0.0861, 0.9851]], grad_fn=<MmBackward0>),\n",
       " tensor([[-0.9386,  0.1854, -0.7626]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vector[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Attention --> (I) x(I)  in I love you`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6069552302360535"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(q_vector[0].squeeze(),k_vector[0].squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2723, 0.2406, 0.7984]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores=[]\n",
    "attention_scores.clear()\n",
    "def calculate_attention(q_vector,k_vector):\n",
    "    for q in q_vector:\n",
    "        word_score=[]\n",
    "        for k in k_vector:\n",
    "            score = torch.dot(q.squeeze(),k.squeeze()).item()\n",
    "            word_score.append(score)\n",
    "\n",
    "        attention_scores.append(word_score.copy())\n",
    "       \n",
    "        word_score.clear()\n",
    "calculate_attention(q_vector,k_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6069552302360535, 1.10406494140625, -0.8198787569999695],\n",
       " [0.9363361597061157, 1.2333495616912842, -0.782888650894165],\n",
       " [-1.505926489830017, -2.297654390335083, 1.7115082740783691]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
