{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([0,1,2])\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8202,  0.8283,  0.2457,  1.1370],\n",
       "         [ 0.1938, -2.9892,  0.5100, -0.1527],\n",
       "         [ 0.0823,  1.3379,  0.5307,  0.5900]], grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Embedding\n",
    "\n",
    "embedding = Embedding(3,4)\n",
    "embedded_sentence =embedding(input)\n",
    "embedded_sentence,embedded_sentence.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q_vector=[]\n",
    "k_vector=[]\n",
    "v_vector=[]\n",
    "q_vector.clear()\n",
    "k_vector.clear()\n",
    "v_vector.clear()\n",
    "\n",
    "Wq = torch.rand(4,3)\n",
    "Wk = torch.rand(4,3)\n",
    "Wv = torch.rand(4,3)\n",
    "\n",
    "\n",
    "for word in embedded_sentence:\n",
    "    q_vector.append(torch.matmul(word.unsqueeze(0),Wq))\n",
    "    k_vector.append(torch.matmul(word.unsqueeze(0),Wk))\n",
    "    v_vector.append(torch.matmul(word.unsqueeze(0),Wv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.7329, 1.6018, 1.7664]], grad_fn=<MmBackward0>),\n",
       " tensor([[-1.9438, -0.9838, -1.2064]], grad_fn=<MmBackward0>),\n",
       " tensor([[1.3765, 1.0368, 1.5225]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[0.9775, 1.6736, 1.0405]], grad_fn=<MmBackward0>),\n",
       "  tensor([[-0.4639, -1.1571, -0.7377]], grad_fn=<MmBackward0>),\n",
       "  tensor([[0.6633, 1.3730, 0.5662]], grad_fn=<MmBackward0>)],\n",
       " torch.Size([1, 3]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_vector , k_vector[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[2.3624, 1.3323, 1.8101]], grad_fn=<MmBackward0>),\n",
       " tensor([[-2.3875, -1.7549, -2.4495]], grad_fn=<MmBackward0>),\n",
       " tensor([[2.2111, 1.4592, 1.7035]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
