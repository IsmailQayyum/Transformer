{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example sentence: `I love you`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), torch.Size([3]))"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([0,1,2])\n",
    "input,input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2990,  0.6139,  0.3475,  1.5683],\n",
       "         [-0.5906, -0.2768, -1.7423,  0.7687],\n",
       "         [-1.3571,  0.3477,  0.4122,  0.2421]], grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Embedding\n",
    "\n",
    "embedding = Embedding(3,4)\n",
    "embedded_sentence =embedding(input)\n",
    "embedded_sentence,embedded_sentence.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q_vector=[]\n",
    "k_vector=[]\n",
    "v_vector=[]\n",
    "q_vector.clear()\n",
    "k_vector.clear()\n",
    "v_vector.clear()\n",
    "\n",
    "Wq = torch.rand(4,3)\n",
    "Wk = torch.rand(4,3)\n",
    "Wv = torch.rand(4,3)\n",
    "\n",
    "\n",
    "for word in embedded_sentence:\n",
    "    q_vector.append(torch.matmul(word.unsqueeze(0),Wq))\n",
    "    k_vector.append(torch.matmul(word.unsqueeze(0),Wk))\n",
    "    v_vector.append(torch.matmul(word.unsqueeze(0),Wv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.7892, 1.4993, 1.0465]], grad_fn=<MmBackward0>),\n",
       " tensor([[-0.5220, -1.1909, -0.5180]], grad_fn=<MmBackward0>),\n",
       " tensor([[ 0.3214, -0.5950, -0.4371]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[1.4714, 1.5221, 1.3076]], grad_fn=<MmBackward0>),\n",
       "  tensor([[-0.8596, -0.9847, -1.0301]], grad_fn=<MmBackward0>),\n",
       "  tensor([[-1.1436, -0.5418,  0.2760]], grad_fn=<MmBackward0>)],\n",
       " torch.Size([1, 3]))"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_vector , k_vector[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.7194, 2.1748, 1.6212]], grad_fn=<MmBackward0>),\n",
       " tensor([[-0.1163, -1.1907, -1.3755]], grad_fn=<MmBackward0>),\n",
       " tensor([[ 0.1521,  0.1838, -0.4775]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.4714, 1.5221, 1.3076]], grad_fn=<MmBackward0>),\n",
       " tensor([[-0.8596, -0.9847, -1.0301]], grad_fn=<MmBackward0>),\n",
       " tensor([[-1.1436, -0.5418,  0.2760]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vector[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Attention --> (I) x(I)  in I love you`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.283153533935547"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(q_vector[0].squeeze(),k_vector[0].squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7892, 1.4993, 1.0465]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores=[]\n",
    "attention_scores.clear()\n",
    "def calculate_attention(q_vector,k_vector):\n",
    "    for q in q_vector:\n",
    "        word_score=[]\n",
    "        for k in k_vector:\n",
    "            score = torch.dot(q.squeeze(),k.squeeze()).item()\n",
    "            word_score.append(score)\n",
    "\n",
    "        attention_scores.append(word_score.copy())\n",
    "       \n",
    "        word_score.clear()\n",
    "calculate_attention(q_vector,k_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6.283153533935547, -4.092398643493652, -2.569571018218994],\n",
       " [-3.2582621574401855, 2.1550886631011963, 1.0992695093154907],\n",
       " [-1.0043386220932007, 0.75986647605896, -0.16579794883728027]]"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_vector[0].squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Normalized Attention Scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.6276, -2.3627, -1.4835],\n",
       "        [-1.8812,  1.2442,  0.6347],\n",
       "        [-0.5799,  0.4387, -0.0957]])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = torch.tensor(attention_scores ) / torch.sqrt(torch.tensor(3))\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9915, 0.0025, 0.0060],\n",
       "        [0.0277, 0.6299, 0.3424],\n",
       "        [0.1855, 0.5136, 0.3010]])"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_scores = torch.softmax(attention_scores, dim=1)\n",
    "activation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(activation_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.7194, 2.1748, 1.6212]], grad_fn=<MmBackward0>),\n",
       " tensor([[-0.1163, -1.1907, -1.3755]], grad_fn=<MmBackward0>),\n",
       " tensor([[ 0.1521,  0.1838, -0.4775]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_scores[0].shape , v_vector[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`S1 x v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7199, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(activation_scores[0],v_vector[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9915, 0.0025, 0.0060])"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_scores[0].shape , v_vector[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(v_vector[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.7194, 2.1748, 1.6212]], grad_fn=<MmBackward0>),\n",
       " tensor([[-0.1163, -1.1907, -1.3755]], grad_fn=<MmBackward0>),\n",
       " tensor([[ 0.1521,  0.1838, -0.4775]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7049, 0.0054, 0.0097], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_scores[0] * v_vector[0].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`New representation for each word`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "SxV = []\n",
    "for s in attention_scores:\n",
    "    weighted_sum=torch.zeros(3)\n",
    "    for i , v in enumerate(v_vector):\n",
    "        weighted_sum += s[i] * v.squeeze()\n",
    "\n",
    "    SxV.append(weighted_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 6.2863, 10.4300,  9.8394], grad_fn=<AddBackward0>),\n",
       " tensor([-3.2826, -5.4561, -5.0643], grad_fn=<AddBackward0>),\n",
       " tensor([-1.0626, -1.8010, -1.4978], grad_fn=<AddBackward0>)]"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SxV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
